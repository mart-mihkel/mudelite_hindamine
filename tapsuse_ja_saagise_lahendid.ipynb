{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1b2f685",
   "metadata": {},
   "source": [
    "$\\DeclareMathOperator*{\\MEAN}{\\mathbf{E}}$\n",
    "$\\DeclareMathOperator*{\\VARIANCE}{\\mathbf{D}}$\n",
    "$\\newcommand{\\mean}[1]{\\MEAN\\left[#1\\right]}$\n",
    "$\\newcommand{\\variance}[1]{\\VARIANCE\\left[#1\\right]}$\n",
    "$\\newcommand{\\prob}[1]{\\Pr\\left[#1\\right]}$\n",
    "$\\newcommand{\\accuracy}{Acc}$\n",
    "$\\newcommand{\\precision}{Prec}$\n",
    "$\\newcommand{\\recall}{Rec}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcce376c",
   "metadata": {},
   "source": [
    "## Täpsuse ja saagise lähendid\n",
    "\n",
    "Populatsiooni või valimi korral, mille klasside sagedus ei ole tasakaalus, võib õigsus olla eksitav hinnang meetodi kvaliteedi kohta.\n",
    "Valimis, mille andmepunktidest 90\\% kuuluvad postiivsesse ning 10\\% negatiivsesse klassi, kõikide andmepunktide postiivseks klassifitseerimine annab õigsuse $\\accuracy=0{,}9$.\n",
    "Lisaks hindab õigsus kõiki klassifitseerimisel tehtud vigu ühtemoodi.\n",
    "Kui valepositiivne või valenegatiive klassifikatsioon võib põhjustada tõsiseid tagajärgi on oluline tehtud vigu üksteisest eristada.\n",
    "\n",
    "Täpsus mõõdab päris positiivsete klassifikatsioonide sagedust ennustatud positiivsete seast.\n",
    "Täpsuse hindamiseks läbi statistilise tõenäosuse on kõigepealt vaja leida kuidas see avaldub tõneäosuste kaudu\n",
    "\\begin{align}\n",
    "    \\precision&=\\mean{A=Y|A=1}=0\\cdot\\prob{A\\neq Y|A=1}+1\\cdot\\prob{A=Y|A=1} \\nonumber\\\\\n",
    "    &=\\prob{Y=1|A=1}=\\frac{\\prob{Y=1\\land A=1}}{\\prob{A=1}} \\enspace. \\label{eq:täpsus tõenäosusesitus}\n",
    "\\end{align}\n",
    "Tulemuse põhjal on võimalik leida hinnang täpsusele üle $N$ andmepunkti suuruse valimi\n",
    "\\begin{equation}\n",
    "    \\label{eq:täpsus lähend}\n",
    "    \\widehat{\\precision}=\\frac{\\frac{1}{N}\\cdot\\sum\\limits_{i=1}^{N}[a_i=1]\\cdot[y_i=1]}{\\frac{1}{N}\\cdot\\sum\\limits_{i=1}^{N}[a_i=1]}=\\frac{\\sum\\limits_{i=1}^{N}[a_i=1]\\cdot[y_i=1]}{\\sum\\limits_{i=1}^{N}[a_i=1]}\\enspace.\n",
    "\\end{equation}\n",
    "\n",
    "Saagis on päris positiivsete klassifikatsioonide sagedus positiivsete andmepunktie seast.\n",
    "Sarnaselt täpsuse tõenäosusesitusele saab saagise esitada tõenäosuste kaudu\n",
    "\\begin{equation*}\n",
    "    \\recall=\\mean{A=Y|Y=1}=\\frac{\\prob{Y=1\\land A=1}}{\\prob{Y=1}} \\enspace,\n",
    "\\end{equation*}\n",
    "mille põhjal on saagise lähend üle valimi arvutatav järgnevalt\n",
    "\\begin{equation}\n",
    "    \\label{eq:saagis lähend}\n",
    "    \\widehat{\\recall}=\\frac{\\frac{1}{N}\\cdot\\sum\\limits_{i=1}^{N}[a_i=1]\\cdot[y_i=1]}{\\frac{1}{N}\\cdot\\sum\\limits_{i=1}^{N}[y_i=1]}=\\frac{\\sum\\limits_{i=1}^{N}[a_i=1]\\cdot[y_i=1]}{\\sum\\limits_{i=1}^{N}[y_i=1]} \\enspace.\n",
    "\\end{equation}\n",
    "\n",
    "Sellisel kujul esitatud lähendite tõenäosuslik hindamine võib olla keeruline, sest nii murru lugejas kui ka nimetajas on ligikaudsed suurused.\n",
    "Lihstam on uurida lähendit üle valimi tinglikust jaotusest.\n",
    "Antud juhul on tingimus kvaliteedimõõdu definitsioonis olev sündmus, näiteks täpsuse puhul $A=1$.\n",
    "Tinglikule jaotusele vastava valimi leidmiseks saab kasutada valikumeetodit (\\emph{rejection sampling}):\n",
    "\n",
    "* Võta jaotusest juhuslik andmepunkt.\n",
    "* Kontrolli andmepunkti vastavust tingimusele.\n",
    "* Kui andmepunkt vastab tingimusele võta see valimisse vastasel juhul mitte.\n",
    "* Korda kuni on leitud soovitud koguses tingimusele vastavaid andmepunkte.\n",
    "\n",
    "Valikumeetodi põhjal on leitav valim $A^{+}$, mis koosneb positiivseks klassifitseeritud andmepunktidest, ning valim $Y^{+}$, mis koosneb positiivse klassiga andmepunktidest.\n",
    "Kasutades vastavaid valimeid on lähendid ja esitatavad kujul:\n",
    "\\begin{align}\n",
    "    \\widehat{\\precision}&=\\frac{1}{|A^{+}|}\\cdot\\sum_{i\\in A^{+}}[y_i=1] \\enspace, \\label{eq:täpsus tinglik lähend}\\\\\n",
    "    \\widehat{\\recall}&=\\frac{1}{|Y^{+}|}\\cdot\\sum_{i\\in Y^{+}}[a_i=1] \\label{eq:saagis tinglik lähend}\\enspace.\n",
    "\\end{align}\n",
    "On oluline tähele panna, et saadud lähendid on analoogsed õigsuse lähendile ning on seetõttu on nende absoluutsed ja relatiivsed vead samasuguste omadustega.\n",
    "\n",
    "Lihtsa valikumeetodi puhul võib osutuda probleemseks tingimuse kontrollimine valimi moodustamisel.\n",
    "Täpsuse puhul on tingimuse kontrollimine lihtne, sest piisab vaid meetodi rakendamisest andmepunktile.\n",
    "Saagise puhul ei pruugi meetod väga hästi toimida, sest tingimuse kontrollimiseks peab välja selgitama andmepunkti tegeliku klassi.\n",
    "Tegeliku klassi leidmine on võrreldes klassifikatsiooni leidmisega kulukas.\n",
    "Valikumeetodi rakendamine saagise lähendamiseks on eriti kulukas, kui positiivse klassiga andmepunktid jaotuses on haruldased.\n",
    "Leidub ülesandeid mille puhul võib positiivse juhtumi esinemissagedus olla $1:10 000$ nagu tekstist faktide eraldamine.\n",
    "Sellisel juhul on $1 000$ elemendilise valimi leidiseks vaja märgendada $10$ miljonit andmepunkti.\n",
    "Isesõitvate autode puhul võivad huvipakkuvad sündumsed esineda ühel korral miljonist ning seega on naiivse lähenemise korral vaja märgendada ligi miljard andmepunkti. Kuid vajaliku töökindluse saavutamiseks peab selliseid sündmusi ikkagi arvestama. \n",
    "See on ka üks põhjus, miks suure töökindlusega praktikas kasutatavte masinõppe algoritmide loomine on keerukas protsess."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
