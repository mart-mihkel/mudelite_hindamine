{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14740ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from plotnine import *\n",
    "from scipy.stats import binom, uniform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce694ac6",
   "metadata": {},
   "source": [
    "$\\DeclareMathOperator*{\\MEAN}{\\mathbf{E}}$\n",
    "$\\DeclareMathOperator*{\\VARIANCE}{\\mathbf{D}}$\n",
    "$\\newcommand{\\mean}[1]{\\MEAN\\left[#1\\right]}$\n",
    "$\\newcommand{\\variance}[1]{\\VARIANCE\\left[#1\\right]}$\n",
    "$\\newcommand{\\prob}[1]{\\Pr\\left[#1\\right]}$\n",
    "$\\newcommand{\\accuracy}{Acc}$\n",
    "$\\newcommand{\\precision}{Prec}$\n",
    "$\\newcommand{\\recall}{Rec}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fa6f8a",
   "metadata": {},
   "source": [
    "## Kvaliteedimõõtude vahede lähendid\n",
    "\n",
    "Kuna defineeritud vahede täpseid väärtusi on praktikas keeruline leida hinnatakse neid kasutades valimi keskmisi. Sealjuures on loomulik mõlema meetodi hindamiseks kasutada sama valimit. Ühelt poolt on see standardpraktika -- tüüpiliselt hinnatakse masinõppemeetodite edukust fikseeritud testvalimite (\\emph{benchmark}) peal. Teisalt tooks kahe valimi kasutamine vajaduse käsitsi märgendada rohkem andmepunkte ning lisab ka lõpptulemusse rohkem juhuslikkust.\n",
    "Kui vastav testvalim sisaldab $N$ andmepunkti, siis saab õigsuste vahe lähendi avaldada järgnevalt\n",
    "\\begin{align}\n",
    "    \\Delta\\widehat{\\accuracy}&=\\frac{1}{N}\\cdot\\sum_{i=1}^{N}[a_i=y_i]-\\frac{1}{N}\\cdot\\sum_{i=1}^{N}[b_i=y_i] \\nonumber\\\\\n",
    "    &=\\frac{1}{N}\\cdot\\sum_{i=1}^{N}[a_i=y_i]-[b_i=y_i]\\nonumber\\\\\n",
    "    &=\\frac{1}{N}\\cdot\\sum_{a_i\\neq b_i}[a_i=y_i]-[b_i=y_i] \\enspace. \\label{eq:õigsus vahe lähend}\n",
    "\\end{align}\n",
    "Saadud võrduses \\eqref{eq:õigsus vahe lähend} on summa märgi all nullist erinev arv parajasti siis, kui meetodite klassifikatsioonid on erinevad.\n",
    "Sellest järeldub, et meetodite õigsuste vahe hindamiseks peab märgendama vaid andmepunkte, kus $a_i\\neq b_i$.\n",
    "Näiteks kui meetodid on üle $90\\%$ õigsustega võivad nende klassifikatsioonid erineda maksimaalselt $20\\%$ andmetest.\n",
    "Sellisel juhul peab märgendama vaid iga viienda andmepunkti.\n",
    "Veelgi enam, kuna iga summa liige valemis  \\eqref{eq:õigsus vahe lähend} on $\\pm 1$, saab hinnata $\\Delta\\widehat{\\accuracy}$ ilma ühtegi andmepunkti märgendamata\n",
    "\\begin{equation}\n",
    "    \\label{eq:õigsus vahe lähend tõke}\n",
    "    |\\Delta\\widehat{\\accuracy}|\\leq\\frac{\\#\\{i: a_i\\neq b_i\\}}{N} \\enspace,\n",
    "\\end{equation}\n",
    "kus murru lugejas tähistab $\\#$ hulga suurust.\n",
    "Seega on võimalik veenduda, kas kaks algoritmi üldse õigsuse poolest erinevad andmepunktide tegelikke klasse teadmata.\n",
    "\n",
    "Analoogselt õigsusele võib avaldada ka valimipõhiste täpsushinnagute vahe\n",
    "\\begin{equation}\n",
    "    \\label{eq:täpsus vahe lähend kole}\n",
    "    \\Delta\\widehat{\\precision}=\\frac{\\sum\\limits_{i=1}^{N}[a_i=1]\\cdot[y_i=1]}{\\sum\\limits_{i=1}^N[a_i=1]}-\n",
    "    \\frac{\\sum\\limits_{i=1}^{N}[b_i=1]\\cdot[y_i=1]}{\\sum\\limits_{i=1}^N [b_i=1]} \\enspace,\n",
    "\\end{equation}\n",
    "mille edasise lihtsustamise muudab raskeks erinevus murru nimetajates.\n",
    "Kuna tehniliselt ei pea täpsuse hidamisel kasutama sama testvalimit mõlema algoritmi jaoks, siis võib esialgset testvalmit kitsendada nii, et murru lugejad langevad kokku\n",
    "\\begin{equation*}\n",
    "    \\sum\\limits_{i=1}^{N_A}[a_i=1]=S=\\sum\\limits_{i=1}^{N_B}[b_i=1] \\enspace,\n",
    "\\end{equation*}\n",
    "ning $N=\\max(N_A, N_B)$.\n",
    "Selline lähenemine on samaväärne valikumeetodi põhjal kahe $S$ andmepunktise valimi moodustamisega, kus vastuvõtutingimused on vastavalt $a_i=1$ ja $b_i=1$.\n",
    "Seda arvestades saab valemi \\eqref{eq:täpsus vahe lähend kole} viia lihtsustatud kujule\n",
    "\\begin{equation}\n",
    "     \\Delta\\widehat{\\precision}=\\frac{1}{S}\\cdot\\sum\\limits_{i=1}^{N_A}[a_i=1]\\cdot[y_i=1]-\\frac{1}{S}\\cdot\\sum\\limits_{i=1}^{N_B}[b_i=1]\\cdot[y_i=1] \\enspace,\n",
    "\\end{equation}\n",
    "kus $a_i$ on määratud vaid esimesel $N_A$ ja $b_i$ on määratud vaid esimesel $N_B$ andmepunktil.\n",
    "Seega on $a_i$ ja $b_i$ väärtus kõigi $N$ punkti seas kas määramata, $0$ või $1$.\n",
    "Siit lähtuvalt\n",
    "\\begin{align}\n",
    "    \\Delta\\widehat{\\precision}&=\\frac{1}{S}\\cdot\\left(\\sum_{\\substack{a_i=1\\\\ b_i=1}}[y_i=1]+\\sum_{\\substack{a_i=1\\\\ b_i\\neq 1}}[y_i=1]-\\sum_{\\substack{a_i=1\\\\ b_i=1}}[y_i=1]-\\sum_{\\substack{a_i\\neq 1\\\\ b_i=1}}[y_i=1]\\right) \\nonumber\\\\\n",
    "    &=\\frac{1}{S}\\cdot\\left(\\sum_{\\substack{a_i=1\\\\ b_i\\neq 1}}[y_i=1]-\\sum_{\\substack{a_i\\neq 1\\\\ b_i=1}}[y_i=1]\\right) \\nonumber\\\\\n",
    "    &=\\frac{1}{S}\\cdot\\sum_{a_i\\neq b_i}[a_i=1]\\cdot[y_i=1]-[b_i=1]\\cdot[y_i=1] \\enspace. \\label{eq:täpsus vahe lähend}\n",
    "\\end{align}\n",
    "Andmepunktide märgendamise mõttes on täpsuse vahe lähend \\eqref{eq:täpsus vahe lähend} samaväärne õigsuse valemiga \\eqref{eq:õigsus vahe lähend}, sest hinnangu arvutamiseks peab märgendama vaid andmepunkte, mille puhul $a_i\\neq b_i$.\n",
    "\n",
    "Täpsuse vahehinnangu praktiline arvutamine algab $S$ fikseerimisest.\n",
    "Seejärel tuleb valimile rakendada meetodeid kuni kumbki on $S$ andmepunkti positiivseks klassifitseerinud.\n",
    "Märgendama peab valimi andmepunktid, mille puhul on olemas mõlema meetodi klassifikatsioonid, mis on üksteisest erinevad.\n",
    "Nüüd on võimalik arvuta summa liikmete väärtused ning seejärel hinnang täpsuste vahele.\n",
    "Sellega on oluliselt vähendadut märgendamist vajavate andmete hulka.\n",
    "\n",
    "Saagise vahe avaldub sarnaselt täpsusele, lähtudes valemist\n",
    "\\begin{equation*}\n",
    "    \\Delta\\widehat{\\recall}=\\frac{\\sum\\limits_{i=1}^{N}[a_i=1]\\cdot[y_i=1]}{\\sum\\limits_{i=1}^{N}[y_i=1]}-\\frac{\\sum\\limits_{i=1}^{N}[b_i=1]\\cdot[y_i=1]}{\\sum\\limits_{i=1}^{N}[y_i=1]} \\enspace,\n",
    "\\end{equation*}\n",
    "kus erinevalt täpsusest on murdude nimetajad definitsiooni järgi võrdsed.\n",
    "Tähistagu nimetajas olevat summat\n",
    "\\begin{equation*}\n",
    "    T=\\sum_{i=1}^N[y_i=1] \\enspace.\n",
    "\\end{equation*}\n",
    "Korrates täpsuse valemi \\eqref{eq:täpsus vahe lähend} tuletamisega analoogset mõttekäiku, võib esitada saagise vahe hinnangu kujul\n",
    "\\begin{equation}\n",
    "    \\label{eq:saagis vahe lähend}\n",
    "     \\Delta\\widehat{\\recall}=\\frac{1}{T}\\cdot\\sum_{a_i\\neq b_i}[a_i=1]\\cdot[y_i=1]-[b_i=1]\\cdot[y_i=1] \\enspace. \n",
    "\\end{equation}\n",
    "Märgendamise seisukohalt on $T$ arvutamine kulukas, kuna iga summa liikme puhul peab teadma andmepunkti tegelikku klassi.\n",
    "Kõigi $N$ andmepunkti manuaalne märgendamine on väga resursimahukas. \n",
    "Alternatiiviks on väiksema valimi põhjal positiivse klassi esinemise sageduse ennustamine. \n",
    "See on võimalik vaid siis kui positiivse klassi esinemise sagedus on piisavalt suur.\n",
    "Kui positiivse klassi esindajad on sagedusega $1:1000$, siis on tarvis adekvaatse hinnagu saamiseks läbi vaadata üle kümnetuhande andmepunkti. \n",
    "Seega on valemi \\eqref{eq:saagis vahe lähend} praktiline rakendamine raskendatud veelgi madalama esinemisagedusega sündmuste korral."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
